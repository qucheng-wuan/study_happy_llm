随着2022底Chatgpt再一次刷新NLP的能力上限，大语言模型（Large Language Model,LLM)开始接替传统的预训练模型（Pre-trained Language Model，PLM）

---
## 4.1.1 LLM的定义

LLM使用与传统预训练语言模型相似的架构与预训练任务（如Decoder-Only架构与CLM预训练任务），但**拥有更庞大的参数、在更海量的语料进行预训练**，从而展现出与传统预训练语言模型截然不同的能力。

一般来说，LLM指包含数百亿（或更多）参数的语言模型，它们往往在数T token语料上通过多卡分布式集群进行预训练，具备远超传统预训练模型的文本理解与生成能力。

一般认为，GPT3（1750亿参数）是 LLM 的开端，基于GPT-3通过预训练（Pretraining）、监督微调（Supervised Fine-Tuning，SFT),强化学习与人类反馈（Reinforcement Learning with Human Feedback，RLHF）三阶段训练得到的Chatgpt更是主导了LLM时代的到来

---
## 4.1.2 LLM的能力
### （1）涌现能力
区分LLM与传统PLM最显著的特征即是LLM具备**涌现能力**
涌现能力是指同样的模型架构与预训练任务下，某些能力在小型模型中不明显，但在大型模型中特别突出。可以类比物理学中的相变现象，涌现能力的显现就像是模型性能随着模型规模增大而迅速提升，超过了随机水平，也就是我们常说的量变引起了质变。

### （2）上下文学习能力（In-context Learning）
具体而言，上下文学习能力是指**允许语言模型在提供自然语指令或多个任务示例的情况下，通过理解上下文并生成相应输出的方式来执行任务，而无需额外的训练或参数更新。**

而具备上下文学习能力的 LLM 往往无需进行高成本的额外训练或微调，而可以通过少数示例或是调整自然语言指令，来处理绝大部分任务，从而大大节省了算力和数据成本

对比：
在传统的PLM时代，解决NLP下游任务的一般范式是预训练-微调，即选用一个合适的预训练模型，针对自己的下游任务准备有监督数据来进行微调。
而通过使用具备上下文学习能力的LLM，一般范式开始向Prompt Engineering 也就是**调整Prompt来激发LLM的能力转变**。
（Eg.目前绝大部分NLP任务，通过调整Prompt或提供 1~5 个自然语言示例，就可以令 GPT-4 达到超过传统 PLM 微调的效果。）

----
### （3）指令遵循（Instruction Following）
通过使用自然语言描述的多任务数据进行微调，也就是所谓的 `指令微调` ，LLM 被证明在同样使用指令形式化描述的未见过的任务上表现良好。也就是说，**经过指令微调的 LLM 能够理解并遵循未见过的指令，并根据任务指令执行任务，而无需事先见过具体示例，这展示了其强大的泛化能力**。

我们只需要在指令微调阶段混合多种指令来训练其泛化能力，LLM 就可以处理人类绝大部分指令，即可以灵活地解决用户遇到的问题。

---
### （4) 逐步推理（Step by Step Reasoning）
逻辑推理，尤其是涉及多个推理步骤的复杂推理任务，一直是NLP的攻关难点。
但是，传统的NLP模型通常难以解决涉及多个推理步骤的复杂任务，例如数学问题。然而，LLM通常采用**思维链（Chain-of-Thought,CoT)推理策略，可以利用包含中间推理步骤的提示机制来解决这些任务，从而得出最终答案。据推测，这种能力可能是通过对代码的训练获得的。**

其实就关注几个提升点就ok
涌现能力 上下文推理能力 指令遵循能力 逐步推理能力

---
## 4.1.3 LLM的特点
除上文讨论的LLM的核心能力外，LLM还具备一些额外的、有趣或是危险的特点，这些特点也是LLM目前重要的研究方向
### （1） 多语言支持
LLM训练语料往往是多语言的，因此LLM天生具有多语言、跨语言能力，
只是随着训练语料和指令微调的差异，在不同语言上有所差异。

### （2）长文本处理
由于能够处理多长的上下文文本，在一定程度上决定了模型的部分能力上限，LLM 往往比传统 PLM 更看重长文本处理能力。
同时，LLM 大部分采用了旋转位置编码（Rotary Positional Encoding，RoPE）（或者同样具有外推能力的 AliBi）作为位置编码，具有一定的长度外推能力，也就是在推理时能够处理显著长于训练长度的文本。

### （3）拓展多模态
LLM的强大能力也为其带来了跨模态的强大表现。
随着LLM的不断改进，**通过为LLM增加额外的参数来进行图像表示**，从而利用LLM的强大能力打造支持文字、图像双模态的模型。
**通过引入Adapter层和图像编辑器，并针对性在图文数据上进行有监督微调，模型能够具备不错的图文问答甚至生成能力**。
在未来，如何对齐文本与图像的表示，从而打造更大的多模态大模型，将 LLM 的能力辐射到更多模态，是一个重要的研究方向。

### （4）挥之不去的幻觉
幻觉，是指 LLM 根据 Prompt 杜撰生成虚假、错误信息的表现。
例如，当我们要求 LLM 生成一篇学术论文及其参考文献列表时，其往往会捏造众多看似“一本正经”实则完全不存在的论文和研究。
幻觉问题是 LLM 的固有缺陷，也是目前 LLM 研究及应用的巨大挑战。尤其是在医学、金融学等非常强调精准、正确的领域，幻觉的存在可能造成非常严重的后果。目前也有很多研究提供了削弱幻觉的一些方法，如 Prompt 里进行限制、通过 RAG（检索增强生成）来指导生成等，但都还只能一定程度减弱幻觉而无法彻底根除。