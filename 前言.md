最开始以注意力机制为模型架构，通过预训练-微调的阶段思想通过在海量无监督文本上进行自监督训练，实现了强大的自然语言理解能力。但是传统的PLM依赖于一定量有监督数据进行下游任务微调，且在自然语言生成任务上性能还不尽人意，NLP系统的性能距离人们所期待的通用人工智能还有不小的差距。

为开发者提供一站式开源 LLM 部署、推理、微调的使用教程：https://github.com/datawhalechina/self-llm
指导开发者从零开始搭建自己的 LLM 应用:
https://github.com/datawhalechina/llm-universe


我觉得词向量这个地方是需要好好理解的